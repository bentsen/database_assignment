{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-05T10:58:12.513435Z",
     "start_time": "2024-03-05T10:58:12.392956Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "dataset_1 = pd.read_csv('2016_-_Citywide_GHG_Emissions_20240207.csv')\n",
    "dataset_2 = pd.read_csv('2017_-_Cities_Community_Wide_Emissions.csv')\n",
    "dataset_3 = pd.read_csv('2017_-_Cities_Emissions_Reduction_Targets_20240207.csv')\n",
    "dataset_4 = pd.read_csv('2023_Cities_Climate_Risk_and_Vulnerability_Assessments_20240207.csv')\n",
    "dataset_5 = pd.read_csv('2016_-_Cities_Emissions_Reduction_Targets_20240207.csv')\n",
    "\n",
    "# Function to prepare and rename columns\n",
    "def prepare_dataset(dataset, col_mappings, cols_to_add):\n",
    "    # Rename columns\n",
    "    dataset = dataset.rename(columns=col_mappings)\n",
    "    # Add missing columns as NaN\n",
    "    for col in cols_to_add:\n",
    "        if col not in dataset.columns:\n",
    "            dataset[col] = pd.NA\n",
    "    return dataset\n",
    "\n",
    "# Column mappings for each dataset\n",
    "col_mappings_1 = {\n",
    "    'City Name': 'city', \n",
    "    'City GDP': 'city_gdp', \n",
    "    'Current Population': 'city_population', \n",
    "    'Country': 'country', \n",
    "        'Total CO2 emissions (metric tonnes CO2e)': 'emission'\n",
    "}\n",
    "\n",
    "col_mappings_2 = {\n",
    "    'City': 'city', \n",
    "    'GDP': 'city_gdp', \n",
    "    'Population': 'city_population', \n",
    "    'Country': 'country', \n",
    "    'Total City-wide emissions (metric tonnes CO2e)': 'emission'\n",
    "}\n",
    "\n",
    "col_mappings_3 = {\n",
    "    'City': 'city', \n",
    "    'Country': 'country', \n",
    "    'Sector': 'sector', \n",
    "    'Baseline emissions (metric tonnes CO2e)': 'emission', \n",
    "    'Percentage reduction target': 'emission_target'\n",
    "}\n",
    "\n",
    "col_mappings_4 = {\n",
    "    'Organization Name': 'city', \n",
    "    'Country/Area': 'country', \n",
    "    'Population': 'city_population'\n",
    "}\n",
    "\n",
    "col_mappings_5 = {\n",
    "    'Organisation': 'city', \n",
    "    'Country': 'country', \n",
    "    'Sector': 'sector', \n",
    "    'Baseline emissions (metric tonnes CO2e)': 'emission', \n",
    "    'Percentage reduction target': 'emission_target'\n",
    "}\n",
    "\n",
    "# Prepare each dataset\n",
    "dataset_1_prepared = prepare_dataset(dataset_1, col_mappings_1, ['sector', 'emission_target', 'emission_status'])\n",
    "dataset_2_prepared = prepare_dataset(dataset_2, col_mappings_2, ['sector', 'emission_target', 'emission_status'])\n",
    "dataset_3_prepared = prepare_dataset(dataset_3, col_mappings_3, ['city_gdp', 'city_population', 'emission_status'])\n",
    "dataset_4_prepared = prepare_dataset(dataset_4, col_mappings_4, ['city_gdp', 'emission', 'sector', 'emission_target', 'emission_status'])\n",
    "dataset_5_prepared = prepare_dataset(dataset_5, col_mappings_5, ['city_gdp', 'city_population', 'emission_status'])\n",
    "\n",
    "# Merge all datasets\n",
    "final_merged_dataset = pd.concat([dataset_1_prepared, dataset_2_prepared, dataset_3_prepared, dataset_4_prepared, dataset_5_prepared])\n",
    "\n",
    "# Select only the specified columns\n",
    "final_selected_columns_dataset = final_merged_dataset[[\n",
    "    'city', 'city_gdp', 'city_population', 'country', 'emission', 'emission_status', 'emission_target', 'sector'\n",
    "]]\n",
    "\n",
    "# Save the selected columns dataset\n",
    "final_selected_columns_dataset.to_csv('selected_columns_merged_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "dataset_2016_targets = pd.read_csv('2016_-_Cities_Emissions_Reduction_Targets_20240207.csv')\n",
    "dataset_2016_ghg = pd.read_csv('2016_-_Citywide_GHG_Emissions_20240207.csv')\n",
    "dataset_2017_community = pd.read_csv('2017_-_Cities_Community_Wide_Emissions.csv')\n",
    "dataset_2017_targets = pd.read_csv('2017_-_Cities_Emissions_Reduction_Targets_20240207.csv')\n",
    "dataset_2023_risk = pd.read_csv('2023_Cities_Climate_Risk_and_Vulnerability_Assessments_20240207.csv')\n",
    "\n",
    "# Function to prepare and rename columns\n",
    "def prepare_dataset(dataset, year, col_mappings):\n",
    "    dataset = dataset.rename(columns=col_mappings)\n",
    "    dataset['year'] = year\n",
    "    return dataset\n",
    "\n",
    "# Define column mappings for each dataset\n",
    "col_mappings_2016_targets = {\n",
    "    'City Name': 'city', \n",
    "    'Country': 'country', \n",
    "    'Baseline emissions (metric tonnes CO2e)': 'emission', \n",
    "    'Target date': 'emission_target',\n",
    "    'Baseline year':'baseline_year',\n",
    "    'Percentage reduction target': 'target',\n",
    "    'Sector':'sector'\n",
    "}\n",
    "col_mappings_2016_ghg = {\n",
    "    'City Name': 'city', \n",
    "    'Country': 'country', \n",
    "    'Total CO2 emissions (metric tonnes CO2e)': 'emission',\n",
    "    'City GDP': 'city_gdp', \n",
    "    'Current Population': 'city_population', \n",
    "    'Increase/Decrease from last year':'year_status',\n",
    "    'Reporting Year':'year'\n",
    "}\n",
    "\n",
    "\n",
    "col_mappings_2017_community = {\n",
    "    'City': 'city', \n",
    "    'Country': 'country', \n",
    "    'Total emissions (metric tonnes CO2e)': 'emission',\n",
    "    'GDP': 'city_gdp', \n",
    "    'Population': 'city_population', \n",
    "    'Increase/Decrease from last year':'year_status',\n",
    "    'Reporting Year':'year'\n",
    "}\n",
    "\n",
    "col_mappings_2017_targets = {\n",
    "    'City': 'city', \n",
    "    'Country': 'country', \n",
    "    'Baseline emissions (metric tonnes CO2e)': 'emission', \n",
    "    'Target date': 'emission_target',\n",
    "    'Baseline year':'baseline_year',\n",
    "    'Percentage reduction target': 'target',\n",
    "    'Sector':'sector'\n",
    "}\n",
    "\n",
    "col_mappings_2023_risk = {\n",
    "    'City': 'city', \n",
    "    'Country/Area': 'country',\n",
    "    'Year of publication or approval': 'year',\n",
    "    'Factors considered in assessment': 'factors',\n",
    "    'Population': 'city_population', \n",
    "}\n",
    "\n",
    "# Prepare each dataset\n",
    "dataset_2016_targets_prepared = prepare_dataset(dataset_2016_targets, 2016, col_mappings_2016_targets)\n",
    "dataset_2016_ghg_prepared = prepare_dataset(dataset_2016_ghg, 2016, col_mappings_2016_ghg)\n",
    "dataset_2017_community_prepared = prepare_dataset(dataset_2017_community, 2017, col_mappings_2017_community)\n",
    "dataset_2017_targets_prepared = prepare_dataset(dataset_2017_targets, 2017, col_mappings_2017_targets)\n",
    "dataset_2023_risk_prepared = prepare_dataset(dataset_2023_risk, 2023, col_mappings_2023_risk)\n",
    "\n",
    "# Merge all datasets\n",
    "merged_dataset = pd.concat([\n",
    "    dataset_2016_targets_prepared, \n",
    "    dataset_2016_ghg_prepared, \n",
    "    dataset_2017_community_prepared, \n",
    "    dataset_2017_targets_prepared, \n",
    "    dataset_2023_risk_prepared\n",
    "])\n",
    "\n",
    "# Drop duplicates and keep the latest record for each city per year\n",
    "merged_dataset = merged_dataset.drop_duplicates(subset=['city', 'year'], keep='last')\n",
    "\n",
    "\n",
    "final_selected_columns_dataset = merged_dataset[[\n",
    "    'city', 'city_gdp', 'city_population', 'country', 'emission', 'emission_target', 'target', 'baseline_year', 'year', 'year_status', 'factors', 'sector'\n",
    "]]\n",
    "\n",
    "# Save the merged dataset\n",
    "final_selected_columns_dataset.to_json('merged_dataset.json', orient='records', lines=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T11:53:00.289027Z",
     "start_time": "2024-03-05T11:53:00.182242Z"
    }
   },
   "id": "7039fc14e54404d9",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "685c05e59b2c6daa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
